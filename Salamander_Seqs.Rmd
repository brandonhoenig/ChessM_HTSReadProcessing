---
title: "ChessM_HTSReadProcessing"
author: "Brandon D. Hoenig"
date: '2022-07-09'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(dada2)
library(seqinr)
library(taxonomizr)
library(R.utils)
library(Biostrings)
```

Read in sequences and create list of sample names
```{r}
fnFs <- sort(list.files(pattern= "_R1_001.fastq", full.names = T))
fnRs <- sort(list.files(pattern="_R2_001.fastq", full.names = T))
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

Trim Primers
```{r}
fnFs_trimmed <- file.path("trimmed", paste0(sample.names, "_F_trimmed.fastq.gz"))
fnRs_trimmed <- file.path("trimmed", paste0(sample.names, "_R_trimmed.fastq.gz"))

removePrimers(fn = fnFs, fout = fnFs_trimmed, 
              primer.fwd = "GRYCTGAAAAAYCAATGTTGTATTCAAC")

removePrimers(fn = fnRs, fout = fnRs_trimmed, 
              primer.fwd = "AATGC")

fnFs <- sort(list.files(path = 'trimmed/', pattern= "_F_trimmed.fastq"))
fnRs <- sort(list.files(path = 'trimmed/', pattern= "_R_trimmed.fastq"))
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```


Inspect Quality Plots
```{r}
plotQualityProfile(paste0('trimmed/',fnFs[1:2]))
```

Place filtered files in filtered/ subdirectory
```{r}
filtFs <- file.path("filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path("filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

filter reads
```{r}
out <- filterAndTrim(fwd = paste0("trimmed/", fnFs), # input
                     filt = filtFs, #output
                     rev = paste0("trimmed/", fnRs), # input
                     filt.rev = filtRs, #output
                     rm.phix = T, #remove PhiX reads
                     compress = T, 
                     multithread = F,
                     matchIDs = T)
head(out)
```

Learn Error Rates 
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
```

Plot Error Rates
```{r}
plotErrors(errF, nominalQ=TRUE)
```

Sample Inference
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
dadaFs
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
dadaRs
```

Merge froward and reverse reads
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE, maxMismatch = 0)
```


Construct Sequence Table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

Remove Chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="pooled", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```

write fasta with sequence IDs
```{r}
seqtab.nochim %>% 
  colnames()

write.fasta(sequences = as.list(seqtab.nochim %>% 
              colnames()), 
            names = paste0("seq_", c(1:ncol(seqtab.nochim))),
  as.string = T, file.out = 'output/dada2_processed_sequences.fasta')
```

sequences were then uploaded to BLASTn and downloaded into the 'fromBLASTn' folder
```{r}
seqsFromBLAST <-
read_csv('fromBLASTn/CPAE1U2S013-Alignment-HitTable.csv',col_names = F) %>%
  select(X1, X2, X3, X4, X8, X11, X12)

colnames(seqsFromBLAST) <- c("Seq_ID", "Accession", "Perc_Ident", "Match_Len", "Query_Len", "E_Val", "BitScore")
```

quality filter sequences
```{r}
seqsFromBLAST %>%
  group_by(Seq_ID)  %>% 
  filter(Perc_Ident >=97) %>%
  top_n(n=1, wt = BitScore) %>% 
  ungroup() %>% 
  select(Accession) %>%
  unique() %>%
  write_tsv(., file = 'output/accessionNumbers.tsv')
```

```{r}
accessionNumbers <-
read_tsv('output/accessionNumbers.tsv') 
```

```{r}
seqid_w_taxonomy <-
seqsFromBLAST %>%
  group_by(Seq_ID)  %>% 
  filter(Perc_Ident >= 97) %>%
  top_n(n=1, wt = BitScore) %>%
  left_join(accessionNumbers, by = 'Accession') %>%
  drop_na(Taxonomy) %>% 
  unique() %>% 
  select(Seq_ID, Taxonomy)
```

```{r}
fastaFile <- readDNAStringSet("output/dada2_processed_sequences.fasta")
seq_name = names(fastaFile)
sequence = paste(fastaFile)
seq_df <- data.frame(seq_name, sequence)
```

```{r}

seqid_w_taxonomy %>%
  left_join(seq_df, by = c('Seq_ID' = 'seq_name')) %>%
  select(-Seq_ID) %>% 
  left_join(seqtab.nochim %>%
  as.data.frame() %>% 
  t() %>% 
  as.data.frame() %>%
  rownames_to_column('Sequences'), by = c('sequence' = 'Sequences')) %>% 
  ungroup() %>%
  select(-c(Seq_ID, sequence)) %>%
  group_by(Taxonomy) %>%
  summarize_all(sum) %>% 

```

